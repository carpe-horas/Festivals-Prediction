{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column에 대한 설명\n",
    "'festive_period' : 축제 기간  \n",
    "'cost' : 총비용  \n",
    "'target_a' : a 연령대가 많이 방문하는 축제 {'old' : 장년층, 'family' : 가족 연령대(아이 + 부모), 'youth' : 청년 }  \n",
    "'non_festival_conc' : 비축제 기간 축제 개최 '행정동' 일 평균 외부 방문자 수 / 축제 개최 '시군구' 일 평균 외부 방문자 수\n",
    "'non_local' : 이동통신 데이터 기반 축제 개최 행정동 일 평균 현지인 방문자 수  \n",
    "'non_foreigner' : 이동통신 데이터 기반 축제 개최 행정동 일 평균 외부 방문자 수(외지인+외국인)\n",
    "'month_a' : a 월\n",
    "'~' : 해당 행정 도 or 특별시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhdwj\\AppData\\Local\\Temp\\ipykernel_8896\\2777973399.py:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['festive_period'].fillna(data['festive_period'].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "data = pd.read_csv('../data/df_charac.csv')\n",
    "\n",
    "data.drop(columns='index_y' ,inplace= True)\n",
    "\n",
    "#이상치 처리 함수 정의\n",
    "def iqr(df, columns):\n",
    "    df_clipped = df.copy()\n",
    "    \n",
    "    for column in columns:\n",
    "        Q1 = df[column].quantile(0.25)\n",
    "        Q3 = df[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        lower = Q1 - 1.5 * IQR\n",
    "        upper = Q3 + 1.5 * IQR\n",
    "        \n",
    "        df_clipped[column] = df[column].clip(lower=lower, upper=upper)\n",
    "        \n",
    "    return df_clipped\n",
    "\n",
    "# 한글 column명 영어로 변경\n",
    "data.rename(columns={'축제기간(일)' : \"festive_period\"}, inplace=True)\n",
    "\n",
    "# 축제 기간 nan 값 평균치로 채워넣기.\n",
    "data['festive_period'].fillna(data['festive_period'].mean(), inplace=True)\n",
    "\n",
    "#iqr\n",
    "data = iqr(data, ['visitors'])\n",
    "\n",
    "# str 데이터 one_hot_encoding으로 분리, month는 category에 속해서 굳이 안해도 되는데 1~12월이 숫자가 늘어난다고 방문자 수가 늘어나는 구조는 아니라서 one-hot으로 변경. 약간의 R2 상승을 봤음.\n",
    "data = pd.get_dummies(data, columns=['target'], drop_first=False)\n",
    "data = pd.get_dummies(data, columns=['month'], drop_first=False)\n",
    "data = pd.get_dummies(data, columns=['도'], drop_first=False)\n",
    "\n",
    "#column 명 정리\n",
    "data.columns = ['Unnamed: 0', 'Festival', 'name_year', 'year', 'visitors', 'cost',\n",
    "       'date', 'visit/cost', 'Fe_festival_conc', 'Fe_foreigner', 'Fe_local',\n",
    "       'Fe_navi', 'Fe_tour_fee', 'non_festival_conc', 'non_foreigner',\n",
    "       'non_local', 'non_navi', 'non_tour_fee', 'festive_period',\n",
    "       'target_family', 'target_old', 'target_youth', 'month_1', 'month_2',\n",
    "       'month_3', 'month_4', 'month_5', 'month_6', 'month_7', 'month_8',\n",
    "       'month_9', 'month_10', 'month_11', 'month_12', 'Gangwon','Gyeonggi',\n",
    "                'Gyeongnam', \n",
    "                'Gyeongbuk', \n",
    "                'Gwangju', \n",
    "                'Daegu',\n",
    "                'Daejeon', \n",
    "                'Busan',\n",
    "                'Seoul', \n",
    "                'Sejong', \n",
    "                'Ulsan', \n",
    "                'Incheon', \n",
    "                'Jeonnam', \n",
    "                'Jeonbuk', \n",
    "                'Jeju', \n",
    "                'Chungnam', \n",
    "                'Chungbuk']\n",
    "\n",
    "# train_test_split : target 은 visitors.\n",
    "X = data[['festive_period',\n",
    "          'cost', \n",
    "          'target_family', \n",
    "          'target_old', \n",
    "          'target_youth',\n",
    "          'non_festival_conc',\n",
    "          'non_local',\n",
    "          'non_foreigner',\n",
    "          'month_1', \n",
    "          'month_2',\n",
    "          'month_3', \n",
    "          'month_4', \n",
    "          'month_5', \n",
    "          'month_6', \n",
    "          'month_7', \n",
    "          'month_8',\n",
    "          'month_9', \n",
    "          'month_10', \n",
    "          'month_11', \n",
    "          'month_12',\n",
    "          'Gangwon',\n",
    "          'Gyeonggi',                \n",
    "          'Gyeongnam',                 \n",
    "          'Gyeongbuk',                 \n",
    "          'Gwangju',                 \n",
    "          'Daegu',                \n",
    "          'Daejeon',                \n",
    "          'Busan',                \n",
    "          'Seoul',                 \n",
    "          'Sejong',                 \n",
    "          'Ulsan',                 \n",
    "          'Incheon',                 \n",
    "          'Jeonnam',                 \n",
    "          'Jeonbuk',                 \n",
    "          'Jeju',                 \n",
    "          'Chungnam',                 \n",
    "          'Chungbuk'\n",
    "          ]]\n",
    "Y = data['visitors']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "X, Y, test_size=0.2, random_state=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 평가 함수 evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가 함수 제작. mse 와 R2score 사용. 모델마다 평가할때 evaluate_model로 평가.\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "def evaluate_models(best_visitors, X_test, Y_test):\n",
    "    # Visitors 모델 평가\n",
    "    y_pred = best_visitors.predict(X_test)\n",
    "    mse_visitors = mean_squared_error(Y_test, y_pred)\n",
    "    r2_visitors = r2_score(Y_test, y_pred)\n",
    "\n",
    "\n",
    "    # 결과 출력\n",
    "    print(f\"Visitors Model Performance:\")\n",
    "    print(f\"  MSE: {mse_visitors}\")\n",
    "    print(f\"  R²: {r2_visitors}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visitors Model Performance:\n",
      "  MSE: 2353736549.5034213\n",
      "  R²: 0.6307875684537696\n"
     ]
    }
   ],
   "source": [
    "# train_test 결과값.\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def train_models(X_train, Y_train):\n",
    "    rf_visitors = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    rf_visitors.fit(X_train, Y_train)\n",
    "\n",
    "    return rf_visitors\n",
    "rf_visitors = train_models(X_train, Y_train)\n",
    "\n",
    "evaluate_models(rf_visitors, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best visitors RF : {'max_depth': 18, 'min_samples_split': 3, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "# 그리드 서치를 통한 하이퍼 파라미터 조정\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def tune_rf(X_train, Y_train):\n",
    "    param_grid_rf = {\n",
    "        'n_estimators': np.arange(40, 60, 10),\n",
    "        'max_depth': [16, 17 ,18],\n",
    "        'min_samples_split':  [3,4,5]}\n",
    "\n",
    "    rf_visitors = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "    grid_search_rf_visitors = GridSearchCV(estimator=rf_visitors, param_grid=param_grid_rf, cv=5, scoring='neg_mean_squared_error')\n",
    "    grid_search_rf_visitors.fit(X_train, Y_train)\n",
    "    \n",
    "    print(f\"Best visitors RF : {grid_search_rf_visitors.best_params_}\")\n",
    "\n",
    "    return grid_search_rf_visitors.best_estimator_\n",
    "\n",
    "\n",
    "best_rf_visitors = tune_rf(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visitors Model Performance:\n",
      "  MSE: 2456103963.7405896\n",
      "  R²: 0.6147299846389713\n"
     ]
    }
   ],
   "source": [
    "# RandomForest 모델 평가\n",
    "evaluate_models(best_rf_visitors, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold별 R2 score: [0.45855016 0.71387008 0.59560164 0.44997592 0.67518227 0.50506883\n",
      " 0.70481614 0.63456602 0.39513638 0.58708823]\n",
      "평균 R2 score: 0.5719855659706026\n"
     ]
    }
   ],
   "source": [
    "# K Fold와 cv score 추가로 도입.\n",
    "# grid search에서 이미 cv = 5를 적용하였지만, 각 fold별 변동폭이 커서, 전체 데이터 셋으로 체크.\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "cv_scores = cross_val_score(best_rf_visitors, X, Y, cv=kf)\n",
    "\n",
    "print(\"Fold별 R2 score:\", cv_scores)\n",
    "print(\"평균 R2 score:\", np.mean(cv_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visitors Model Performance:\n",
      "  MSE: 2227631920.3158746\n",
      "  R²: 0.6505686254209959\n"
     ]
    }
   ],
   "source": [
    "# train test 기본 결과값.\n",
    "import xgboost as xgb\n",
    "\n",
    "def train_xgboost(X_train, Y_train):\n",
    "    \n",
    "    xgb_visitors = xgb.XGBRegressor(n_estimators=100, random_state=42)\n",
    "    xgb_visitors.fit(X_train, Y_train)\n",
    "\n",
    "    xgb_vicost = xgb.XGBRegressor(n_estimators=100, random_state=42)\n",
    "    xgb_vicost.fit(X_train, Y_train)\n",
    "    \n",
    "    return xgb_visitors\n",
    "\n",
    "xgb_visitors = train_xgboost(X_train, Y_train)\n",
    "\n",
    "evaluate_models(xgb_visitors, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best xgb visitors: {'colsample_bytree': 0.6, 'learning_rate': 0.03, 'max_depth': 9, 'n_estimators': 100, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "# 그리드 서치로 하이퍼 파라미터 조정\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "def tune_xgb(X_train, Y_train):\n",
    "    param_grid_xgb = {\n",
    "        'n_estimators': np.arange(90,110,10),\n",
    "        'max_depth': [7,8, 9,10],\n",
    "        'learning_rate': [0.03],\n",
    "        'subsample': [0.75,0.8,0.85],\n",
    "        'colsample_bytree': np.arange(0.5, 0.7, 0.1)}\n",
    "\n",
    "    xgb_visitors = xgb.XGBRegressor(random_state=42, n_jobs=-1)\n",
    "    grid_search_xgb_visitors = GridSearchCV(estimator=xgb_visitors, param_grid=param_grid_xgb, cv=5, scoring='neg_mean_squared_error')\n",
    "    grid_search_xgb_visitors.fit(X_train, Y_train)\n",
    "    \n",
    "    print(f\"Best xgb visitors: {grid_search_xgb_visitors.best_params_}\")\n",
    "\n",
    "    return grid_search_xgb_visitors.best_estimator_\n",
    "\n",
    "best_xgb_visitors = tune_xgb(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visitors Model Performance:\n",
      "  MSE: 2409206009.0600166\n",
      "  R²: 0.6220865037387034\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가 함수로 조정된 sgboost 결과 확인.\n",
    "evaluate_models(best_xgb_visitors, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold별 R2 score: [0.52314623 0.71136974 0.66568977 0.48362636 0.65164548 0.52888739\n",
      " 0.68887691 0.64130707 0.47136475 0.67200936]\n",
      "평균 R2 score: 0.6037923061766147\n"
     ]
    }
   ],
   "source": [
    "# K Fold와 cv score 추가로 도입.\n",
    "# grid search에서 이미 cv = 5를 적용하였지만, 각 fold별 변동폭이 커서, 전체 데이터 셋으로 체크.\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "cv_scores = cross_val_score(best_xgb_visitors, X, Y, cv=kf)\n",
    "\n",
    "print(\"Fold별 R2 score:\", cv_scores)\n",
    "print(\"평균 R2 score:\", np.mean(cv_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ===================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientBoostingRegressor -- 최종 선정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visitors Model Performance:\n",
      "  MSE: 2328691116.999703\n",
      "  R²: 0.634716251566489\n"
     ]
    }
   ],
   "source": [
    "#기본 GradientBoosting\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "def train_gradient_boosting(X_train, Y_train):\n",
    "    gb_visitors = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "    gb_visitors.fit(X_train, Y_train)\n",
    "\n",
    "    return gb_visitors\n",
    "\n",
    "gb_visitors = train_gradient_boosting(X_train, Y_train)\n",
    "\n",
    "evaluate_models(gb_visitors, X_test, Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best gb visitors: {'learning_rate': 0.03, 'max_depth': 5, 'n_estimators': 210, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "# 그리드 서치로 하이퍼 파라미터 검정\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "def tune_gb(X_train, Y_train):\n",
    "    param_grid_gb = {\n",
    "        'n_estimators': [190,200,210],\n",
    "        'max_depth': [4, 5, 6],\n",
    "        'learning_rate': [0.04, 0.02, 0.03],\n",
    "        'subsample': [0.7, 0.75, 0.8]}\n",
    "    \n",
    "    gb_visitors = GradientBoostingRegressor(random_state=42)\n",
    "    grid_search_gb_visitors = GridSearchCV(estimator=gb_visitors, param_grid=param_grid_gb, cv=5, scoring='neg_mean_squared_error')\n",
    "    grid_search_gb_visitors.fit(X_train, Y_train)\n",
    "\n",
    "    print(f\"Best gb visitors: {grid_search_gb_visitors.best_params_}\")\n",
    "\n",
    "    return grid_search_gb_visitors.best_estimator_\n",
    "\n",
    "best_gb_visitors = tune_gb(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visitors Model Performance:\n",
      "  MSE: 2286369554.6735315\n",
      "  R²: 0.6413549074248\n"
     ]
    }
   ],
   "source": [
    "# 평가함수로 모델 체크.\n",
    "evaluate_models(best_gb_visitors, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold별 R2 score: [0.53076437 0.71929564 0.7116982  0.46441509 0.67231274 0.56519664\n",
      " 0.78881469 0.72028834 0.48794763 0.66145688]\n",
      "평균 R2 score: 0.6322190225724836\n"
     ]
    }
   ],
   "source": [
    "# K Fold와 cv score 추가로 도입.\n",
    "# grid search에서 이미 cv = 5를 적용하였지만, 각 fold별 변동폭이 커서, 전체 데이터 셋으로 한번 더 체크.\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "cv_scores = cross_val_score(best_gb_visitors, X, Y, cv=kf)\n",
    "\n",
    "print(\"Fold별 R2 score:\", cv_scores)\n",
    "print(\"평균 R2 score:\", np.mean(cv_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train test split만\n",
    "Visitors Model Performance:  \n",
    "  MSE: 2679345855.5847173  \n",
    "  R²: 0.5797117572472353  \n",
    "  \n",
    "# gridsearch 이후.\n",
    "Visitors Model Performance:  \n",
    "  MSE: 2066437694.2304952  \n",
    "  R²: 0.6758539158145839  \n",
    "  \n",
    "# K Fold로 다르게 쪼갰을 때도 같은지 검정.\n",
    "Fold별 R2 score: [0.57802775 0.67556454 0.70368518 0.56395319 0.55637453 0.57743816  \n",
    " 0.76224563 0.70915654 0.5779924  0.66033483]  \n",
    "평균 R2 score: 0.6364772749648543  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ====================\n",
    "# RANSACRegressor -- 망함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visitors Model Performance:\n",
      "  MSE: 6843246960.712327\n",
      "  R²: -0.0734471751177932\n"
     ]
    }
   ],
   "source": [
    "# 기본 train test 값\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "\n",
    "def train_ransac(X_train, Y_train):\n",
    "    ransac_visitors = RANSACRegressor(random_state=42)\n",
    "    ransac_visitors.fit(X_train, Y_train)\n",
    "    \n",
    "    return ransac_visitors\n",
    "\n",
    "ransac_visitors = train_ransac(X_train, Y_train)\n",
    "\n",
    "evaluate_models(ransac_visitors, X_test, Y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best rs visitors: {'max_trials': 50, 'min_samples': 0.7, 'residual_threshold': 20}\n"
     ]
    }
   ],
   "source": [
    "# 그리드 서치로 튜닝\n",
    "\n",
    "def tune_rs(X_train, Y_train):\n",
    "    param_grid_ransac = {\n",
    "        'min_samples': [0.5, 0.7, 0.9],\n",
    "        'residual_threshold': [5, 10, 20],\n",
    "        'max_trials': [50, 100, 150],\n",
    "    }\n",
    "    ransac_visitors = RANSACRegressor(random_state=42)\n",
    "    grid_search_ransac_visitors = GridSearchCV(estimator=ransac_visitors, param_grid=param_grid_ransac, cv=5, scoring='neg_mean_squared_error')\n",
    "    grid_search_ransac_visitors.fit(X_train, Y_train)\n",
    "\n",
    "    print(f\"Best rs visitors: {grid_search_ransac_visitors.best_params_}\")\n",
    "\n",
    "    return grid_search_ransac_visitors.best_estimator_\n",
    "\n",
    "best_rs_visitors = tune_rs(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visitors Model Performance:\n",
      "  MSE: 22596239560.557247\n",
      "  R²: -2.5444971756565486\n"
     ]
    }
   ],
   "source": [
    "#평가 함수로 평가\n",
    "evaluate_models(best_rs_visitors, X_test, Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
